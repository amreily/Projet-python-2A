{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comment j'ai scrappé le NYT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "API_KEY = \"D26RTqR74kjjaopDptodzz8lKomncUTM\"  # clé API NYT\n",
    "QUERY = \"CAC 40\"\n",
    "START_DATE = datetime(2000, 1, 1)  # Début de janvier 2000\n",
    "END_DATE = datetime(2020, 4, 19)   # Fin de novembre 2024\n",
    "OUTPUT_FILE = \"mentions_cac40.csv\"\n",
    "\n",
    "# URL de l'Article Search API\n",
    "BASE_URL = \"https://api.nytimes.com/svc/search/v2/articlesearch.json\"\n",
    "\n",
    "\n",
    "# Fonction pour formater les dates au format AAAAMMJJ\n",
    "def format_date(date):\n",
    "    return date.strftime(\"%Y%m%d\")\n",
    "\n",
    "\n",
    "# Fonction pour récupérer les articles depuis l'API NYT\n",
    "def fetch_articles(query, start_date, end_date, api_key):\n",
    "    all_articles = []\n",
    "    page = 0\n",
    "\n",
    "    print(\"Recherche des articles en cours...\")\n",
    "    while True:\n",
    "        # Préparer les paramètres de la requête\n",
    "        params = {\n",
    "            'q': query,\n",
    "            'begin_date': format_date(start_date),\n",
    "            'end_date': format_date(end_date),\n",
    "            'api-key': api_key,\n",
    "            'page': page,\n",
    "            'sort': 'newest'\n",
    "        }\n",
    "\n",
    "        # Envoyer la requête\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Erreur API : {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        docs = data.get('response', {}).get('docs', [])\n",
    "\n",
    "        if not docs:\n",
    "            break  # Sortir si plus d'articles\n",
    "\n",
    "        # Extraire les données nécessaires\n",
    "        for article in docs:\n",
    "            all_articles.append({\n",
    "                'headline': article['headline']['main'],\n",
    "                'snippet': article.get('snippet', ''),\n",
    "                'pub_date': article.get('pub_date', ''),\n",
    "                'web_url': article.get('web_url', '')\n",
    "            })\n",
    "\n",
    "        print(f\"Page {page + 1} traitée ({len(docs)} articles)\")\n",
    "        page += 1\n",
    "\n",
    "        if page % 5 == 0:\n",
    "            print(\"Pause imposée par l'API...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    return all_articles\n",
    "\n",
    "\n",
    "# Fonction principale\n",
    "def main():\n",
    "    global END_DATE\n",
    "    # Chemin du fichier\n",
    "    file_name = \"mentions_cac40.csv\"\n",
    "\n",
    "    # Tester si le fichier existe\n",
    "    if os.path.isfile(file_name):\n",
    "        # Charger le fichier CSV\n",
    "        df = pd.read_csv(\"mentions_cac40.csv\")\n",
    "\n",
    "        # Convertir la colonne `pub_date` en format datetime\n",
    "        df['pub_date'] = pd.to_datetime(df['pub_date'])\n",
    "\n",
    "        # Trouver la date minimale\n",
    "        derniere_date = df['pub_date'].min()\n",
    "\n",
    "        # Convertir en datetime.date pour garder uniquement la date\n",
    "        if isinstance(derniere_date, pd.Timestamp):\n",
    "            derniere_date = derniere_date.to_pydatetime().date()\n",
    "\n",
    "        # Ajouter un jour à la date\n",
    "        END_DATE = derniere_date + timedelta(days=1)\n",
    "\n",
    "    articles = fetch_articles(QUERY, START_DATE, END_DATE, API_KEY)\n",
    "\n",
    "    if not articles:\n",
    "        print(\"Aucun article trouvé.\")\n",
    "        return\n",
    "\n",
    "    # Sauvegarder les résultats dans un fichier CSV\n",
    "    df = pd.DataFrame(articles)\n",
    "    df.to_csv(OUTPUT_FILE, mode='a', index=False)\n",
    "    print(f\"{len(articles)} articles sauvegardés dans '{OUTPUT_FILE}'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "puis nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV dans un DataFrame\n",
    "df = pd.read_csv(\"mentions_cac40.csv\")\n",
    "\n",
    "# Supprimer les doublons en gardant seulement le premier article par date\n",
    "df_unique = df.drop_duplicates(subset=['pub_date'], keep='first')\n",
    "\n",
    "# Sauvegarder le résultat dans un nouveau fichier CSV\n",
    "df_unique.to_csv(\"mentions_cac40.csv\", index=False)\n",
    "\n",
    "print(\"Traitement terminé. Le fichier 'articles_uniques_par_date.csv' contient les articles sans doublons par date.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "puis compter les articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_path = 'mentions_cac40.csv'  # Chemin du fichier d'entrée\n",
    "output_path = 'nbr_mentions.csv'  # Chemin du fichier de sortie\n",
    "\n",
    "# Lire les données depuis le fichier CSV\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Vérifier si la colonne 'pub_date' existe\n",
    "if 'pub_date' not in df.columns:\n",
    "    raise ValueError(\"La colonne 'pub_date' n'existe pas dans le fichier.\")\n",
    "\n",
    "# Convertir la colonne 'Date' en format datetime\n",
    "try:\n",
    "    df['Date'] = pd.to_datetime(df['pub_date'], errors='coerce')\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Erreur lors de la conversion des dates : {e}\")\n",
    "\n",
    "# Identifier et retirer les valeurs non valides\n",
    "invalid_dates = df[df['Date'].isna()]\n",
    "if not invalid_dates.empty:\n",
    "    print(f\"Dates invalides détectées :\\n{invalid_dates}\")\n",
    "    # Supprimer les lignes avec des dates non valides\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "# Définir les périodes : 1 janvier, 1 mars, 1 juin, 1 septembre\n",
    "def assign_period(date):\n",
    "    if date.month in [1, 2]:\n",
    "        return f\"{date.year}-01-01\"\n",
    "    elif date.month in [3, 4, 5]:\n",
    "        return f\"{date.year}-03-01\"\n",
    "    elif date.month in [6, 7, 8]:\n",
    "        return f\"{date.year}-06-01\"\n",
    "    elif date.month in [9, 10, 11]:\n",
    "        return f\"{date.year}-09-01\"\n",
    "    else:  # Décembre\n",
    "        return f\"{date.year}-12-01\"\n",
    "\n",
    "# Ajouter une colonne pour la période\n",
    "df['Period'] = df['Date'].apply(assign_period)\n",
    "\n",
    "# Grouper par période et compter les articles\n",
    "article_counts = df.groupby('Period').size().reset_index(name='Article Count')\n",
    "\n",
    "# Sauvegarder le résultat dans un nouveau fichier CSV\n",
    "article_counts.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Les résultats ont été sauvegardés dans : {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "après je fais une jointure avec le cac40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les fichiers CSV\n",
    "sortie = pd.read_csv(\"sortie.csv\")\n",
    "nbr_mentions = pd.read_csv(\"nbr_mentions.csv\")\n",
    "\n",
    "# Assurez-vous que les colonnes de date sont au format datetime\n",
    "sortie['Date'] = pd.to_datetime(sortie['Date'], errors='coerce')\n",
    "nbr_mentions['Date'] = pd.to_datetime(nbr_mentions['Date'], errors='coerce')\n",
    "\n",
    "# Effectuer la jointure sur la colonne 'date'\n",
    "resultat = pd.merge(sortie[['Date', 'Close']], nbr_mentions[['Date', 'Article Count']], on='Date', how='inner')\n",
    "\n",
    "# Sauvegarder le fichier résultant si nécessaire\n",
    "resultat.to_csv(\"jointure_resultat.csv\", index=False)\n",
    "\n",
    "print(\"La jointure a été réalisée avec succès. Le fichier est sauvegardé sous le nom 'jointure_resultat.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "puis plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cac40_and_mentions(csv_file):\n",
    "    # Load the CSV data into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert the 'Date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Plot CAC40 Close values (left y-axis) as a line\n",
    "    ax1.plot(df['Date'], df['Close'], color='blue', label='CAC40 (Close)')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('CAC40 Close', color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    # Create a second y-axis for Article Count\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Invert the y-axis for Article Count and plot as bars\n",
    "    ax2.bar(df['Date'], df['Article Count'], color='orange', alpha=0.6, width=20, label='Article Count')\n",
    "    ax2.set_ylabel('Article Count', color='orange')\n",
    "    ax2.tick_params(axis='y', labelcolor='orange')\n",
    "    ax2.invert_yaxis()\n",
    "\n",
    "    # Add legends and title\n",
    "    fig.legend(loc=\"upper left\", bbox_to_anchor=(0.1, 0.9))\n",
    "    plt.title('CAC40 Close vs Article Count Over Time')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the CSV file name\n",
    "plot_cac40_and_mentions('jointure_resultat.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
